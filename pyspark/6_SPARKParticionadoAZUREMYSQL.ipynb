{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xr-S8FXX0vKx"
      },
      "source": [
        "# Particionado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nFCY4dv0vK1"
      },
      "source": [
        "## Creamos una sesión de spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ghp6QJOtKUq7"
      },
      "source": [
        "# Nueva sección"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwnmIFc60vK2",
        "outputId": "a62c55b0-c67c-4117-d533-4a335a1c2612"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting py4j==0.10.9.7 (from pyspark)\n",
            "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=b1437e565a52a18a8ab576ec8286c4bde18de16cac42643d16ac74b7cabe0cf0\n",
            "  Stored in directory: /home/datormx/.cache/pip/wheels/38/df/61/8c121f50c3cffd77f8178180dd232d90b3b99d1bd61fb6d6be\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.7 pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBXtcj3W0vK3"
      },
      "source": [
        "Spark permite desde la creación de la sesión o contexto, indicar la cantidad de particiones que tendremos\n",
        "\n",
        "Para esto debemos de indicar con '[ ]'  en la indicación de master la cantidad total de particiones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IVkpYnZ70vK4"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.appName(\"Particionado\") \\\n",
        ".master( \"local[5]\").config(\"spark.driver.extraClassPath\", \"/content/sample_data/mysql-connector-j-8.3.0.jar\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ik2_IRK0vK4",
        "outputId": "7bb63791-e7f1-4f2c-d8f4-3fe986551980"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = spark.range(0,20)\n",
        "df.rdd.getNumPartitions()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFPurwkt0vK4"
      },
      "source": [
        "El método 'parallelize', permite la asignar manualmente la cantidad de particiones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWwvkO9D0vK4",
        "outputId": "9ed2cac0-03be-40b2-a7b0-032a7d8d9643"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdd1 = spark.sparkContext.parallelize((0,20),6)\n",
        "rdd1.getNumPartitions()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYTgaWXu0vK5"
      },
      "source": [
        "Del mismo modo cuandore creamos un RDD o DF, podemos hacer esto.\n",
        "\n",
        "En el caso de los RDD se realiza de la siguiente forma\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hZhKVr1A0vK5"
      },
      "outputs": [],
      "source": [
        "rddDesdeArchivo = spark \\\n",
        "    .sparkContext \\\n",
        "    .textFile(\"/content/sample_data/deporte.csv\",10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2B1R_gi3Jz7",
        "outputId": "df9fcf82-e833-49d9-f51a-d31967387d14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+--------------------+\n",
            "|deporte_id|      nombre_deporte|\n",
            "+----------+--------------------+\n",
            "|        34|      Figure Skating|\n",
            "|        21|              Hockey|\n",
            "|        15|       Alpine Skiing|\n",
            "|        14|    Art Competitions|\n",
            "|        22|              Rowing|\n",
            "|        28|           Taekwondo|\n",
            "|        35|                Golf|\n",
            "|        44|    Freestyle Skiing|\n",
            "|        66|         Aeronautics|\n",
            "|        51|        Snowboarding|\n",
            "|        31|            Canoeing|\n",
            "|        46|        Trampolining|\n",
            "|        39|Synchronized Swim...|\n",
            "|        53|Short Track Speed...|\n",
            "|        59|        Motorboating|\n",
            "|        23|           Bobsleigh|\n",
            "|        41|     Nordic Combined|\n",
            "|        52|               Rugby|\n",
            "|        30|              Diving|\n",
            "|        24|             Fencing|\n",
            "+----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dfmysqlazure = spark.read.format(\"jdbc\") \\\n",
        "    .option(\"url\", \"jdbc:mysql://mysqlservertestafabflexible.mysql.database.azure.com:3306/deportes\") \\\n",
        "    .option(\"driver\", \"com.mysql.cj.jdbc.Driver\") \\\n",
        "    .option(\"dbtable\", \"deporte\") \\\n",
        "    .option(\"user\", \"mysqladmin\") \\\n",
        "    .option(\"password\", \"Andres1980\") \\\n",
        "    .load()\n",
        "\n",
        "dfmysqlazure = dfmysqlazure.repartition(20)\n",
        "\n",
        "# Mostrar los datos leídos\n",
        "dfmysqlazure.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUtZrpY-UucG",
        "outputId": "8600ac54-848e-4fd0-bedb-666319aebd6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número de particiones: 20\n"
          ]
        }
      ],
      "source": [
        "num_partitions = dfmysqlazure.rdd.getNumPartitions()\n",
        "print(\"Número de particiones:\", num_partitions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AM2jgcB0vK5",
        "outputId": "7a039664-bb9d-4c64-ffd3-a476cea9c0af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número de particiones: 10\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "rddDesdeArchivo.getNumPartitions()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OjoUVST0vK6"
      },
      "source": [
        "Es una buena practica tener los archivos de datos particionados para una carga mas rápida y mejor administración.\n",
        "\n",
        "El método 'saveAsTextFile' permite almacenar los archivos, particionados o no, en un ruta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yG-oRYwYU3Xt"
      },
      "outputs": [],
      "source": [
        "rddDesdeArchivo.saveAsTextFile(\"/home/spark/Downloads/salidastexto/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIk5-jGnYK9q"
      },
      "source": [
        "Convertir DataFrame a RDD y guardar como texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0t_Zt2ciYGZE"
      },
      "outputs": [],
      "source": [
        "dfmysqlazure.rdd.map(lambda row: \",\".join([str(i) for i in row])).saveAsTextFile(\"/home/spark/Downloads/salidastexto2/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFUdGPtv0vK6"
      },
      "outputs": [],
      "source": [
        "rddDesdeArchivo.saveAsTextFile(\"/home/spark/Downloads/salidastexto/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoqRl2-l0vK7",
        "outputId": "8b9668e2-c413-4362-cec1-64e32290e017"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "part-00000  part-00002\tpart-00004  part-00006\tpart-00008  _SUCCESS\n",
            "part-00001  part-00003\tpart-00005  part-00007\tpart-00009\n"
          ]
        }
      ],
      "source": [
        "!ls /home/spark/Downloads/salidastexto/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpH3c9ad0vK7"
      },
      "source": [
        "A continuación se muestra como cargar los multiples archivos en un mismo RDD.\n",
        "\n",
        "Esta operación tambien se puede realizar para DF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "4FmU8FMSahjn"
      },
      "outputs": [],
      "source": [
        "rdd2 = spark.sparkContext.wholeTextFiles(\"/home/spark/Downloads/salidastexto2/*\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NczdbfvO0vK7"
      },
      "outputs": [],
      "source": [
        "rdd = spark.sparkContext.wholeTextFiles(\"/home/spark/Downloads/salidastexto/*\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "FEW7VfEPaq-f"
      },
      "outputs": [],
      "source": [
        "lista = rdd2.mapValues(lambda x : x.split()).collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rkD41z_80vK7"
      },
      "outputs": [],
      "source": [
        "lista = rdd.mapValues(lambda x : x.split()).collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "BUYrCmBs0vK8"
      },
      "outputs": [],
      "source": [
        "l = [l[0] for l in lista]\n",
        "l.sort()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w10Oh685a6pu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "jVUn8fuO0vK9"
      },
      "outputs": [],
      "source": [
        "rddDesdeArchivo = spark \\\n",
        "    .sparkContext \\\n",
        "    .textFile(','.join(l),\n",
        "              10).map(lambda l : l.split(\",\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypZlVMHj0vK9",
        "outputId": "de9e816a-1ba6-4847-9fb8-543aa2a85745"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['34', 'Figure Skating'],\n",
              " ['21', 'Hockey'],\n",
              " ['15', 'Alpine Skiing'],\n",
              " ['14', 'Art Competitions'],\n",
              " ['22', 'Rowing'],\n",
              " ['28', 'Taekwondo'],\n",
              " ['35', 'Golf'],\n",
              " ['44', 'Freestyle Skiing'],\n",
              " ['66', 'Aeronautics'],\n",
              " ['51', 'Snowboarding'],\n",
              " ['31', 'Canoeing'],\n",
              " ['46', 'Trampolining'],\n",
              " ['39', 'Synchronized Swimming'],\n",
              " ['53', 'Short Track Speed Skating'],\n",
              " ['59', 'Motorboating'],\n",
              " ['23', 'Bobsleigh'],\n",
              " ['41', 'Nordic Combined'],\n",
              " ['52', 'Rugby'],\n",
              " ['30', 'Diving'],\n",
              " ['24', 'Fencing'],\n",
              " ['38', 'Volleyball'],\n",
              " ['3', 'Football'],\n",
              " ['62', 'Jeu De Paume'],\n",
              " ['4', 'Tug-Of-War'],\n",
              " ['58', 'Racquets'],\n",
              " ['17', 'Weightlifting'],\n",
              " ['37', 'Archery'],\n",
              " ['2', 'Judo'],\n",
              " ['27', 'Boxing'],\n",
              " ['5', 'Speed Skating'],\n",
              " ['42', 'Baseball'],\n",
              " ['48', 'Triathlon'],\n",
              " ['8', 'Ice Hockey'],\n",
              " ['60', 'Military Ski Patrol'],\n",
              " ['64', 'Alpinism'],\n",
              " ['33', 'Modern Pentathlon'],\n",
              " ['19', 'Luge'],\n",
              " ['18', 'Wrestling'],\n",
              " ['7', 'Athletics'],\n",
              " ['1', 'Basketball'],\n",
              " ['16', 'Handball'],\n",
              " ['57', 'Cricket'],\n",
              " ['61', 'Croquet'],\n",
              " ['56', 'Polo'],\n",
              " ['50', 'Curling'],\n",
              " ['49', 'Ski Jumping'],\n",
              " ['36', 'Softball'],\n",
              " ['6', 'Cross Country Skiing'],\n",
              " ['43', 'Rhythmic Gymnastics'],\n",
              " ['55', 'Lacrosse'],\n",
              " ['65', 'Basque Pelota'],\n",
              " ['12', 'Biathlon'],\n",
              " ['10', 'Badminton'],\n",
              " ['11', 'Sailing'],\n",
              " ['45', 'Rugby Sevens'],\n",
              " ['32', 'Tennis'],\n",
              " ['29', 'Cycling'],\n",
              " ['26', 'Shooting'],\n",
              " ['13', 'Gymnastics'],\n",
              " ['20', 'Water Polo'],\n",
              " ['63', 'Roque'],\n",
              " ['54', 'Skeleton'],\n",
              " ['9', 'Swimming'],\n",
              " ['25', 'Equestrianism'],\n",
              " ['40', 'Table Tennis'],\n",
              " ['47', 'Beach Volleyball']]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rddDesdeArchivo.take(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCqQAZkH0vK9",
        "outputId": "7ac86d3d-b9a2-4802-d735-3f7f453157c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X65SnGgUMY9F"
      },
      "outputs": [],
      "source": [
        "spark"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
